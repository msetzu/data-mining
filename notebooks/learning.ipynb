{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "## Init\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "from objects import *\n",
    "from settings import *\n",
    "\n",
    "\n",
    "hr = HR(data)\n",
    "df = hr.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Preprocessing.\n",
    "\n",
    "satisfactions = lambda x: 0 if x <= 5 else 1 if x <= 8 else 2\n",
    "hours = lambda x: 0 if x <= 160.5 else 1 if x <= 210.5 else 2 if x <= 240 else 3\n",
    "projects = lambda x: 0 if x <= 3 else 1 if x <= 5 else 2\n",
    "time_spent = lambda x: 0 if x <= 3 else 1 if x <= 5 else 2\n",
    "\n",
    "\n",
    "def preprocess(df):\n",
    "    \"\"\"\n",
    "    Turn the given dataframe's variables into numerical ones, able to be handled by the scikit-learn algorithms.\n",
    "    :param df    The dataframe to process.\n",
    "    :return      A dictionary\n",
    "                    d = {\n",
    "                        \"df\": Dataframe where categorical/ordinal variables are replaced by an integer mapping.,\n",
    "                        \"mappings\": The mappings created by the preprocessing phase.\n",
    "                    }\n",
    "    \"\"\"\n",
    "    df_prime = df\n",
    "    columns = df.columns\n",
    "    \n",
    "    features_types = {feature: set(map(type,set(df[feature]))) for feature in columns}\n",
    "    str_features = list({feature: types for feature, types in features_types.items() if str in types})\n",
    "    mappings = {}\n",
    "    \n",
    "    for str_feature in str_features:\n",
    "        values = set(df_prime[str_feature].values)\n",
    "        mapping = {value: key for value, key in zip(values,range(len(values)))}\n",
    "        df_prime[str(str_feature)] = pd.Series(df_prime[str_feature]).map(mapping)\n",
    "            \n",
    "        mappings[str_feature] = mapping\n",
    "    \n",
    "    df_prime[\"satisfaction_level\"] = pd.Series(df_prime[\"satisfaction_level\"]).map(satisfactions)\n",
    "    df_prime[\"average_montly_hours\"] = pd.Series(df_prime[\"average_montly_hours\"]).map(hours)\n",
    "    df_prime[\"number_project\"] = pd.Series(df_prime[\"number_project\"]).map(projects)\n",
    "    df_prime[\"time_spend_company\"] = pd.Series(df_prime[\"time_spend_company\"]).map(time_spent)\n",
    "    \n",
    "    return {\"df\": df_prime, \"mappings\": mappings}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Tree drawing definitions.\n",
    "import pydotplus \n",
    "from IPython.display import Image\n",
    "\n",
    "\n",
    "def draw_tree(dot_data, pretty_prints):\n",
    "    graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "    Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "## Compute decision trees.\n",
    "from sklearn import metrics\n",
    "\n",
    "import graphviz\n",
    "\n",
    "import pickle\n",
    "\n",
    "\n",
    "min_samples_leaf = 50\n",
    "max_depths = range(2,6)\n",
    "\n",
    "roots = labels\n",
    "banned_features = set([\"Work_accident\", \"sales\", \"idx\"])\n",
    "roots = set(roots) - banned_features\n",
    "trees = {}\n",
    "\n",
    "df[\"satisfaction_level\"] = hr.discrete[\"satisfaction_level\"]\n",
    "\n",
    "df_prime = preprocess(df)[\"df\"]\n",
    "df_prime[\"last_evaluation\"] = hr.discrete[\"last_evaluation\"]\n",
    "\n",
    "for max_depth in max_depths:\n",
    "    trees[max_depth] = {}\n",
    "    \n",
    "    for metric in [\"entropy\", \"gini\"]:\n",
    "        trees[max_depth][metric] = {}\n",
    "        decision_tree = tree.DecisionTreeClassifier(criterion=metric,\n",
    "                                                min_samples_leaf=min_samples_leaf,\n",
    "                                                max_depth=max_depth)\n",
    "\n",
    "        for root in roots:\n",
    "            columns = list(roots)\n",
    "            columns.remove(root)\n",
    "\n",
    "            train_data, test_data, train_target, test_target = train_test_split(df_prime[columns].values,\n",
    "                                                                                df_prime[root].values,\n",
    "                                                                                test_size=.2,\n",
    "                                                                                random_state=0)\n",
    "            \n",
    "            trees[max_depth][metric][root] = {}\n",
    "            \n",
    "            # Training\n",
    "            trees[max_depth][metric][root][\"train\"] = {}\n",
    "            trained_model = decision_tree.fit(train_data, train_target)\n",
    "            validation_on_training_set = decision_tree.predict(train_data)\n",
    "                                              \n",
    "            trees[max_depth][metric][root][\"train\"][\"tree\"] = (trained_model, list(roots))\n",
    "            \n",
    "            # Training measures\n",
    "            trees[max_depth][metric][root][\"train\"][\"precision\"] = metrics.precision_score(train_target,\n",
    "                                                                    validation_on_training_set,\n",
    "                                                                    average=\"weighted\")\n",
    "            trees[max_depth][metric][root][\"train\"][\"recall\"] = metrics.recall_score(train_target,\n",
    "                                                                 validation_on_training_set,\n",
    "                                                                 average=\"weighted\")\n",
    "            trees[max_depth][metric][root][\"train\"][\"f1\"] = metrics.f1_score(train_target,\n",
    "                                                             validation_on_training_set,\n",
    "                                                             average=\"weighted\")\n",
    "            trees[max_depth][metric][root][\"train\"][\"accuracy\"] = metrics.accuracy_score(train_target, validation_on_training_set)\n",
    "            trees[max_depth][metric][root][\"train\"][\"support\"] = metrics.precision_recall_fscore_support(train_target, validation_on_training_set)\n",
    "            \n",
    "            \n",
    "            # Validation\n",
    "            trees[max_depth][metric][root][\"test\"] = {}\n",
    "            test_on_training_set = decision_tree.predict(test_data)\n",
    "            \n",
    "            # Validation measures\n",
    "            trees[max_depth][metric][root][\"test\"][\"accuracy\"] = metrics.accuracy_score(test_target, test_on_training_set)\n",
    "            trees[max_depth][metric][root][\"test\"][\"confusion matrix\"] = metrics.confusion_matrix(test_target, test_on_training_set)\n",
    "            \n",
    "            # Export\n",
    "            tree.export_graphviz(decision_tree,\n",
    "                                 out_file=\"tree.\" + str(max_depth)\n",
    "                                             + \".\" + str(metric)\n",
    "                                             + \".\" + str(labels_pretty_print[root])\n",
    "                                             + \".dot\",\n",
    "                                 feature_names=columns,\n",
    "                                 leaves_parallel=True,\n",
    "                                 proportion=True,\n",
    "                                 rounded=True)\n",
    "\n",
    "\n",
    "with open(\"trees.pickle\", \"wb\") as log:\n",
    "    pickle.dump(file=log, obj=trees, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
